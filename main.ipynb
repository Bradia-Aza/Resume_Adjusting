{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ead3da-666e-4a37-813d-1bde239035cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9d34bc-65c1-45fd-ae2a-83c2dd85d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bardia/Coding/LangChain/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pickle\n",
    "from src.data_loader import extract_latex_dependencies, build_resume_context, flatten_pydantic, rebase_dependency_paths, convert_profile_latex\n",
    "from src.llm_tools import enrich_file_metadata, extract_jd_features, tailor_profile_and_highlights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414dfe1e-0da3-4667-b190-7620d3d8065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "# check for the cache file containing all the dependencies and load it if it exists\n",
    "cache_dir = \"./cache\"\n",
    "# check the validity of the cache directory\n",
    "if not os.path.exists(cache_dir):\n",
    "    raise FileNotFoundError(f\"The directory was not found: ' {cache_dir} ' \")\n",
    "\n",
    "cache_file_name = \"resume_metadata.pkl\"\n",
    "cache_path = os.path.join(cache_dir, cache_file_name)\n",
    "\n",
    "if os.path.exists(cache_path): \n",
    "    with open(cache_path, 'rb') as f: \n",
    "        dep_list = pickle.load(f)\n",
    "        print(\"File loaded\")\n",
    "#else proccess the latex main file for the dependencies list\n",
    "else: \n",
    "    rsm_main_path = \"./Rsm/main/Resume_Bardia_Azami/resume-general/Bardia-Azami-Resume.tex\"\n",
    "    #check the validity of file path \n",
    "    if not os.path.exists(rsm_main_path): \n",
    "        raise FileNotFoundError(f\"The directory was not found: ' {rsm_main_path} ' \")\n",
    "    #unproccesed dependencies list\n",
    "    dep_unprc = extract_latex_dependencies(rsm_main_path)\n",
    "    #enrich the dependencies list \n",
    "    dep_list = enrich_file_metadata(dep_unprc)\n",
    "    print(\"dependencies extracted\")\n",
    "    #save the list \n",
    "    with open(cache_path, 'wb') as f: \n",
    "        pickle.dump(dep_list, f)\n",
    "        print(\"The proccesed dependencies saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c90f9b9-8d98-4546-a91f-80ad8a20fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebasing paths...\n",
      "FROM: ./Rsm/main/Resume_Bardia_Azami\n",
      "TO:   ./Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directories\n",
    "jd_dir = \"./Rsm/jd\"\n",
    "rsm_dir = \"./Rsm/main/Resume_Bardia_Azami\"\n",
    "rsm_tailored_path =\"./Rsm/tailored\"\n",
    "for path in [jd_dir, rsm_dir, rsm_tailored_path]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileExistsError(f\"could not find the job description file:{jd_dir} \")\n",
    "\n",
    "# list all .tex files in jd directory\n",
    "tex_files = [f for f in os.listdir(jd_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "# create destination folders for tailored resumes and copy the main resume for making adjusments\n",
    "for tex_file in tex_files: \n",
    "    target_dir = os.path.join( rsm_tailored_path , os.path.splitext(tex_file)[0] )\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    destination = os.path.join(target_dir, os.path.basename(rsm_dir))\n",
    "    if not os.path.exists(destination):\n",
    "        shutil.copytree(rsm_dir, destination)\n",
    "\n",
    "    #update dep list for the tailored resume path \n",
    "    new_dep_list = rebase_dependency_paths(dep_list , destination, rsm_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622b535a-9aea-43f0-8b06-bdcf35b21b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'section': 'CONTACT_INFORMATION',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/background.tex',\n",
       "  'title': 'Contact Information'},\n",
       " {'section': 'PROFILE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/Profile.tex',\n",
       "  'title': 'Professional Summary'},\n",
       " {'section': 'HIGHLIGHT OF QUALIFICATIONS',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/Qualifications/QualificationsHighlight.tex',\n",
       "  'title': 'Qualifications Summary'},\n",
       " {'section': 'TECHNICAL EXPERIENCE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/experiences/BSS.tex',\n",
       "  'title': 'Computer Vision Engineer - Behyar Sanaat Sepahan'},\n",
       " {'section': 'TECHNICAL EXPERIENCE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/experiences/Researcher-UI.tex',\n",
       "  'title': 'AI Researcher - Univ of Isfahan'},\n",
       " {'section': 'TECHNICAL EXPERIENCE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/Projects/Housing.tex',\n",
       "  'title': 'Machine Learning Engineer - Ottawa Housing Demand Analysis'},\n",
       " {'section': 'TECHNICAL EXPERIENCE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/Projects/NLP.tex',\n",
       "  'title': 'AI Agent Developer â€“ RAG-Based QA System (WW2 Dataset)'},\n",
       " {'section': 'TECHNICAL EXPERIENCE',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/Projects/ROS2.tex',\n",
       "  'title': 'Robotics Engineer - Algonquin College'},\n",
       " {'section': 'TECHNICAL SKILLS',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/skills.tex',\n",
       "  'title': 'Technical Skills'},\n",
       " {'section': 'EDUCATION',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/education/Education.tex',\n",
       "  'title': 'AI & Software Developer - Algonquin College'},\n",
       " {'section': 'AWARDS',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/awards/DataDays.tex',\n",
       "  'title': 'First place at Sharif DataDays 2022'},\n",
       " {'section': 'AWARDS',\n",
       "  'full_path': './Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/components/awards/Torob.tex',\n",
       "  'title': 'Third place at Torob Data Challenge 2023'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee0213-a92d-4d05-80be-facc170331a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMP\n",
    "jd_path = \"./Rsm/jd/GPTZero(Machine Learning Intern).txt\"\n",
    "\n",
    "if not os.path.exists(jd_path):\n",
    "    raise FileNotFoundError(f\"File not found: {jd_file_path}\")\n",
    "        \n",
    "try:\n",
    "    with open(jd_path, 'r', encoding='utf-8') as f:\n",
    "        jd = f.read()\n",
    "except Exception as e:\n",
    "    raise IOError(f\"Error reading file: {e}\")\n",
    "    \n",
    "jd_kw = extract_jd_features(jd)\n",
    "\n",
    "#TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb024a5-1525-4e06-bda9-f1e5e34c0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_kw_ls = flatten_keywords(jd_kw , ['domain_knowledge', 'technical_stack', 'tools_and_platforms', 'soft_skills'])\n",
    "print(len(jd_kw_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118622e-5c55-46ea-ac44-783cf32ce6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm = build_resume_context(dep_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be8811-d050-4b8f-ab62-08fe64dc24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tailor_profile_and_highlights(rsm, jd, jd_kw_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71bded-e48f-4655-8d5f-73adfca5c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile, hl_qualifications = convert_profile_latex(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
