{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ead3da-666e-4a37-813d-1bde239035cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e9d34bc-65c1-45fd-ae2a-83c2dd85d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pickle\n",
    "from src.data_loader import extract_latex_dependencies, build_resume_context, flatten_pydantic\n",
    "from src.data_loader import rebase_dependency_paths, convert_to_latex, create_dep_map, write_section_content\n",
    "from src.llm_tools import enrich_file_metadata, extract_jd_features, tailor_profile_and_highlights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "414dfe1e-0da3-4667-b190-7620d3d8065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "# check for the cache file containing all the dependencies and load it if it exists\n",
    "cache_dir = \"./cache\"\n",
    "# check the validity of the cache directory\n",
    "if not os.path.exists(cache_dir):\n",
    "    raise FileNotFoundError(f\"The directory was not found: ' {cache_dir} ' \")\n",
    "\n",
    "cache_file_name = \"resume_metadata.pkl\"\n",
    "cache_path = os.path.join(cache_dir, cache_file_name)\n",
    "\n",
    "if os.path.exists(cache_path): \n",
    "    with open(cache_path, 'rb') as f: \n",
    "        dep_list = pickle.load(f)\n",
    "        print(\"File loaded\")\n",
    "#else proccess the latex main file for the dependencies list\n",
    "else: \n",
    "    rsm_main_path = \"./Rsm/main/Resume_Bardia_Azami/resume-general/Bardia-Azami-Resume.tex\"\n",
    "    #check the validity of file path \n",
    "    if not os.path.exists(rsm_main_path): \n",
    "        raise FileNotFoundError(f\"The directory was not found: ' {rsm_main_path} ' \")\n",
    "    #unproccesed dependencies list\n",
    "    dep_unprc = extract_latex_dependencies(rsm_main_path)\n",
    "    #enrich the dependencies list \n",
    "    dep_list = enrich_file_metadata(dep_unprc)\n",
    "    print(\"dependencies extracted\")\n",
    "    #save the list \n",
    "    with open(cache_path, 'wb') as f: \n",
    "        pickle.dump(dep_list, f)\n",
    "        print(\"The proccesed dependencies saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5daa5d1c-5ff5-4e72-8a79-4730ed1fb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mpping function from the llm output keys to the extracted dependencies keys \n",
    "LLM_TO_RESUME_BRIDGE = {\n",
    "    # -- Summaries --\n",
    "    \"profile\": (\"PROFILE\", \"Professional Summary\"),\n",
    "    \"highlights\": (\"HIGHLIGHT OF QUALIFICATIONS\", \"Qualifications Summary\"), \n",
    "    # -- Experience / Projects --\n",
    "    \"housing_project\": (\"TECHNICAL EXPERIENCE\", \"Machine Learning Engineer - Ottawa Housing Demand Analysis\"),\n",
    "    \"nlp_project\": (\"TECHNICAL EXPERIENCE\", \"AI Agent Developer â€“ RAG-Based QA System (WW2 Dataset)\"),\n",
    "    \"ros2_project\": (\"TECHNICAL EXPERIENCE\", \"Robotics Engineer - Algonquin College\"),\n",
    "    \"behyar_job\": (\"TECHNICAL EXPERIENCE\", \"Computer Vision Engineer - Behyar Sanaat Sepahan\"),\n",
    "    \"ui_research\": (\"TECHNICAL EXPERIENCE\", \"AI Researcher - Univ of Isfahan\"),\n",
    "    # -- Skills --\n",
    "    \"skills\": (\"TECHNICAL SKILLS\", \"Technical Skills\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c90f9b9-8d98-4546-a91f-80ad8a20fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebasing paths...\n",
      "FROM: ./Rsm/main/Resume_Bardia_Azami\n",
      "TO:   ./Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directories\n",
    "jd_dir = \"./Rsm/jd\"\n",
    "rsm_dir = \"./Rsm/main/Resume_Bardia_Azami\"\n",
    "rsm_tailored_path =\"./Rsm/tailored\"\n",
    "for path in [jd_dir, rsm_dir, rsm_tailored_path]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileExistsError(f\"could not find the job description file:{jd_dir} \")\n",
    "\n",
    "# list all .tex files in jd directory\n",
    "tex_files = [f for f in os.listdir(jd_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "# create destination folders for tailored resumes and copy the main resume for making adjusments\n",
    "for tex_file in tex_files: \n",
    "    target_dir = os.path.join( rsm_tailored_path , os.path.splitext(tex_file)[0] )\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    destination = os.path.join(target_dir, os.path.basename(rsm_dir))\n",
    "    if not os.path.exists(destination):\n",
    "        shutil.copytree(rsm_dir, destination)\n",
    "\n",
    "    #update dep list for the tailored resume path \n",
    "    new_dep_list = rebase_dependency_paths(dep_list , destination, rsm_dir)\n",
    "    dep_map = create_dep_map(new_dep_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbee0213-a92d-4d05-80be-facc170331a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Mining keywords (High Recall)...\n",
      "Minerd found 40 potential keywords.\n",
      "Step 2: Judging keywords (High Precision)...\n",
      "Judge has finished filtering.\n"
     ]
    }
   ],
   "source": [
    "#TEMP\n",
    "jd_path = \"./Rsm/jd/GPTZero(Machine Learning Intern).txt\"\n",
    "\n",
    "if not os.path.exists(jd_path):\n",
    "    raise FileNotFoundError(f\"File not found: {jd_file_path}\")\n",
    "        \n",
    "try:\n",
    "    with open(jd_path, 'r', encoding='utf-8') as f:\n",
    "        jd = f.read()\n",
    "except Exception as e:\n",
    "    raise IOError(f\"Error reading file: {e}\")\n",
    "    \n",
    "jd_kw = extract_jd_features(jd)\n",
    "\n",
    "#TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eb024a5-1525-4e06-bda9-f1e5e34c0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "jd_kw_ls = flatten_pydantic(jd_kw , ['domain_knowledge', 'technical_stack', 'tools_and_platforms', 'soft_skills'])\n",
    "print(len(jd_kw_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9118622e-5c55-46ea-ac44-783cf32ce6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm = build_resume_context(dep_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5be8811-d050-4b8f-ab62-08fe64dc24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tailor_profile_and_highlights(rsm, jd, jd_kw_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b71bded-e48f-4655-8d5f-73adfca5c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: Professional Summary\n",
      "Updated: Qualifications Summary\n"
     ]
    }
   ],
   "source": [
    "for keys in data.keys():\n",
    "    latex_data = convert_to_latex( data[keys] )\n",
    "    section, title = LLM_TO_RESUME_BRIDGE[keys]\n",
    "    write_section_content(dep_map, section , title , latex_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
