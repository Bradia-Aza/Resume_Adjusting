{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86ead3da-666e-4a37-813d-1bde239035cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e9d34bc-65c1-45fd-ae2a-83c2dd85d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pickle\n",
    "from src.data_loader import extract_latex_dependencies, build_resume_context, flatten_pydantic\n",
    "from src.data_loader import rebase_dependency_paths, convert_to_latex, create_dep_map, write_section_content, exp_reorder\n",
    "from src.llm_tools import enrich_file_metadata, extract_jd_features, tailor_profile_and_highlights, rank_experiences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "414dfe1e-0da3-4667-b190-7620d3d8065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "# check for the cache file containing all the dependencies and load it if it exists\n",
    "cache_dir = \"./cache\"\n",
    "# check the validity of the cache directory\n",
    "if not os.path.exists(cache_dir):\n",
    "    raise FileNotFoundError(f\"The directory was not found: ' {cache_dir} ' \")\n",
    "\n",
    "cache_file_name = \"resume_metadata.pkl\"\n",
    "cache_path = os.path.join(cache_dir, cache_file_name)\n",
    "\n",
    "if os.path.exists(cache_path): \n",
    "    with open(cache_path, 'rb') as f: \n",
    "        dep_list = pickle.load(f)\n",
    "        print(\"File loaded\")\n",
    "#else proccess the latex main file for the dependencies list\n",
    "else: \n",
    "    rsm_main_path = \"./Rsm/main/Resume_Bardia_Azami/resume-general/Bardia-Azami-Resume.tex\"\n",
    "    #check the validity of file path \n",
    "    if not os.path.exists(rsm_main_path): \n",
    "        raise FileNotFoundError(f\"The directory was not found: ' {rsm_main_path} ' \")\n",
    "    #unproccesed dependencies list\n",
    "    dep_unprc = extract_latex_dependencies(rsm_main_path)\n",
    "    #enrich the dependencies list \n",
    "    dep_list = enrich_file_metadata(dep_unprc)\n",
    "    print(\"dependencies extracted\")\n",
    "    #save the list \n",
    "    with open(cache_path, 'wb') as f: \n",
    "        pickle.dump(dep_list, f)\n",
    "        print(\"The proccesed dependencies saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5daa5d1c-5ff5-4e72-8a79-4730ed1fb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mpping function from the llm output keys to the extracted dependencies keys \n",
    "LLM_TO_RESUME_BRIDGE = {\n",
    "    # -- Summaries --\n",
    "    \"profile\": (\"PROFILE\", \"Professional Summary\"),\n",
    "    \"highlights\": (\"HIGHLIGHT OF QUALIFICATIONS\", \"Qualifications Summary\"), \n",
    "    # -- Experience / Projects --\n",
    "    \"housing_project\": (\"TECHNICAL EXPERIENCE\", \"Machine Learning Engineer - Ottawa Housing Demand Analysis\"),\n",
    "    \"nlp_project\": (\"TECHNICAL EXPERIENCE\", \"AI Agent Developer â€“ RAG-Based QA System (WW2 Dataset)\"),\n",
    "    \"ros2_project\": (\"TECHNICAL EXPERIENCE\", \"Robotics Engineer - Algonquin College\"),\n",
    "    \"behyar_job\": (\"TECHNICAL EXPERIENCE\", \"Computer Vision Engineer - Behyar Sanaat Sepahan\"),\n",
    "    \"ui_research\": (\"TECHNICAL EXPERIENCE\", \"AI Researcher - Univ of Isfahan\"),\n",
    "    # -- Skills --\n",
    "    \"skills\": (\"TECHNICAL SKILLS\", \"Technical Skills\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c90f9b9-8d98-4546-a91f-80ad8a20fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebasing paths...\n",
      "FROM: ./Rsm/main/Resume_Bardia_Azami\n",
      "TO:   ./Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directories\n",
    "jd_dir = \"./Rsm/jd\"\n",
    "rsm_dir = \"./Rsm/main/Resume_Bardia_Azami\"\n",
    "rsm_tailored_path =\"./Rsm/tailored\"\n",
    "for path in [jd_dir, rsm_dir, rsm_tailored_path]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileExistsError(f\"could not find the job description file:{jd_dir} \")\n",
    "\n",
    "# list all .tex files in jd directory\n",
    "tex_files = [f for f in os.listdir(jd_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "# create destination folders for tailored resumes and copy the main resume for making adjusments\n",
    "for tex_file in tex_files: \n",
    "    target_dir = os.path.join( rsm_tailored_path , os.path.splitext(tex_file)[0] )\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    destination = os.path.join(target_dir, os.path.basename(rsm_dir))\n",
    "    if not os.path.exists(destination):\n",
    "        shutil.copytree(rsm_dir, destination)\n",
    "\n",
    "    #update dep list for the tailored resume path \n",
    "    new_dep_list = rebase_dependency_paths(dep_list , destination, rsm_dir)\n",
    "    dep_map = create_dep_map(new_dep_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbee0213-a92d-4d05-80be-facc170331a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Mining keywords (High Recall)...\n",
      "Minerd found 40 potential keywords.\n",
      "Step 2: Judging keywords (High Precision)...\n",
      "Judge has finished filtering.\n"
     ]
    }
   ],
   "source": [
    "#Extract key Words\n",
    "jd_path = \"./Rsm/jd/GPTZero(Machine Learning Intern).txt\"\n",
    "\n",
    "if not os.path.exists(jd_path):\n",
    "    raise FileNotFoundError(f\"File not found: {jd_file_path}\")\n",
    "        \n",
    "try:\n",
    "    with open(jd_path, 'r', encoding='utf-8') as f:\n",
    "        jd = f.read()\n",
    "except Exception as e:\n",
    "    raise IOError(f\"Error reading file: {e}\")\n",
    "    \n",
    "jd_kw = extract_jd_features(jd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eb024a5-1525-4e06-bda9-f1e5e34c0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "jd_kw_ls = flatten_pydantic(jd_kw , ['domain_knowledge', 'technical_stack', 'tools_and_platforms', 'soft_skills'])\n",
    "print(len(jd_kw_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9118622e-5c55-46ea-ac44-783cf32ce6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tailor profile and highlight of qualifications\n",
    "rsm = build_resume_context(dep_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5be8811-d050-4b8f-ab62-08fe64dc24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tailor_profile_and_highlights(rsm, jd, jd_kw_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b71bded-e48f-4655-8d5f-73adfca5c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: Professional Summary\n",
      "Updated: Qualifications Summary\n"
     ]
    }
   ],
   "source": [
    "for keys in data.keys():\n",
    "    latex_data = convert_to_latex( data[keys] )\n",
    "    section, title = LLM_TO_RESUME_BRIDGE[keys]\n",
    "    write_section_content(dep_map, section , title , latex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53054dc7-4f64-41c3-97b5-26c1ccfafbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorde experiences \n",
    "dep_list_exp = [dep for dep in dep_list if dep['section'] == 'TECHNICAL EXPERIENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "366db5d5-7bbd-4b0b-a086-780d3650d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_key_list = [key for key, (section, title) in LLM_TO_RESUME_BRIDGE.items() if section == \"TECHNICAL EXPERIENCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c105d1b-daac-43bb-bb43-73db3ce79025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_exp = build_resume_context(dep_list_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc65a08f-6c3a-4c65-ac4f-22deb4c70329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Asking LLM to rank experiences based on context...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nlp_project', 'housing_project', 'ros2_project', 'ui_research', 'behyar_job']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ranked = rank_experiences(jd, exp_key_list, rsm_exp)\n",
    "exp_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1db6c040-83be-4c2d-ad67-3c08e8990989",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.path.join(destination, 'resume-general/Bardia-Azami-Resume.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65e91205-c7b4-457c-87c0-038eafa70422",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path_bridge  = {\n",
    "    \"behyar_job\": r\"\\subimport{../components/experiences/}{BSS.tex}\",\n",
    "    \"ui_research\": r\"\\subimport{../components/experiences/}{Researcher-UI.tex}\",\n",
    "    \"housing_project\": r\"\\subimport{../components/Projects}{Housing.tex}\",\n",
    "    \"nlp_project\": r\"\\subimport{../components/Projects}{NLP.tex}\",\n",
    "    \"ros2_project\": r\"\\subimport{../components/Projects}{ROS2.tex}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41f96846-fc79-4ab6-88c8-98ad6179de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully reordered 5 experiences in ./Rsm/tailored/GPTZero(Machine Learning Intern)/Resume_Bardia_Azami/resume-general/Bardia-Azami-Resume.tex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_reorder(main_path, exp_ranked, exp_path_bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70235f-6704-4fdd-9a43-393f020a5050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
